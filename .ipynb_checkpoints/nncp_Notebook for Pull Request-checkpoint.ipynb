{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 60.3 GiB for an array with shape (90000, 90000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-55f4c8c36e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m weightsinit, factorsinit = initialize_cp(tensor, rank, init=init, svd=svd,\n\u001b[0m\u001b[1;32m     30\u001b[0m                                  \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                  normalize_factors=False)\n",
      "\u001b[0;32m~/tensorly/tensorly/decomposition/_cp.py\u001b[0m in \u001b[0;36minitialize_cp\u001b[0;34m(tensor, rank, init, svd, random_state, normalize_factors)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Put SVD initialization on the same scaling as the tensor in case normalize_factors=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorly/tensorly/backend/core.py\u001b[0m in \u001b[0;36mpartial_svd\u001b[0;34m(self, matrix, n_eigenvecs, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_matrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0m\u001b[1;32m    129\u001b[0m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 60.3 GiB for an array with shape (90000, 90000) and data type float64"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac,non_negative_parafac\n",
    "import time\n",
    "from tensorly.metrics.regression import RMSE\n",
    "from tensorly.decomposition._nn_cp import CP_NN_HALS, non_negative_parafac_hals\n",
    "from scipy.misc import face\n",
    "from skimage.metrics import structural_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorly.decomposition._cp import initialize_cp\n",
    "from tensorly.cp_tensor import CPTensor\n",
    "from tensorly.testing import assert_array_equal, assert_\n",
    "from tensorly.random import check_random_state, random_cp\n",
    "#image\n",
    "image = face()\n",
    "image = tl.tensor(image, dtype='float')[:300,:300,:]\n",
    "\n",
    "#hyperspectral image\n",
    "#mat = scipy.io.loadmat('../data/Indian_pines_corrected.mat')\n",
    "#image=mat['indian_pines_corrected']\n",
    "\n",
    "\n",
    "tensor=tl.tensor(image,dtype='float')\n",
    "#parameters\n",
    "init='svd'\n",
    "svd='numpy_svd'\n",
    "rank=25\n",
    "\n",
    "weightsinit, factorsinit = initialize_cp(tensor, rank, init=init, svd=svd,\n",
    "                                 random_state=None,\n",
    "                                 normalize_factors=False)\n",
    "\n",
    "cpinit=CPTensor((weightsinit,factorsinit))\n",
    "\n",
    "print(tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorly Nonnegative Parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "weightsnon, factorsnon = non_negative_parafac(tensor, rank=rank, init=cpinit, tol=10e-8)\n",
    "cp_reconstructionnon = tl.cp_to_tensor((weightsnon, factorsnon))\n",
    "time_tensorlynon = time.time()-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hals in Tensorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticnew = time.time()\n",
    "nncp=CPNN_HALS(rank=rank,init=cpinit)\n",
    "cptensor=nncp.fit_transform(tensor)\n",
    "cp_reconstruction_hals = tl.cp_to_tensor(cptensor)\n",
    "time_class = time.time()-ticnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for tensorly noncp: 0.7674345970153809\n",
      "time for hals in tensorly: 2.2427027225494385\n",
      "RMSE tensorly ncp: 13.49321531452301\n",
      "RMSE Hals in tensorly: 8.679729593463863\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_error(im1, im2):\n",
    "    r, c, b = im1.shape\n",
    "    sim = tl.zeros(b)\n",
    "    rmse = tl.zeros(b)\n",
    "    for i in range(b):\n",
    "        sim[i] = structural_similarity(im1[:, :, i], im2[:, :, i])\n",
    "        rmse[i] = RMSE(im1[:, :, i], im2[:, :, i])\n",
    "\n",
    "    return sim, rmse\n",
    "def errors_for_each(a,b,c):\n",
    "    ssimb,rmseb=calculate_error(a,b)\n",
    "    ssimc,rmsec=calculate_error(a,c)\n",
    "\n",
    "    fig=plt.figure()\n",
    "    fig.set_size_inches(10, fig.get_figheight(), forward=True)\n",
    "    plt.plot(rmseb)\n",
    "    plt.plot(rmsec)\n",
    "    plt.title('RMSE')\n",
    "    plt.legend(['ncp', 'hals'], loc='upper left')\n",
    "    fig=plt.figure()\n",
    "    fig.set_size_inches(10, fig.get_figheight(), forward=True)\n",
    "    plt.plot(ssimb)\n",
    "    plt.plot(ssimc)\n",
    "    plt.legend(['ncp','hals'], loc='upper left')\n",
    "    plt.title('SSIM')\n",
    "print('time for tensorly noncp:'+' ' +str(time_tensorlynon))\n",
    "print('time for hals in tensorly:'+' ' +str(time_class))\n",
    "print('RMSE tensorly ncp:'+' ' +str(RMSE(tensor,cp_reconstructionnon)))\n",
    "print('RMSE Hals in tensorly:'+' ' +str(RMSE(tensor,cp_reconstruction_hals)))\n",
    "errors_for_each(tensor,cp_reconstructionnon,cp_reconstruction_hals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Backend to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('tensorflow')\n",
    "tensor=tl.tensor(image,dtype='float')\n",
    "test_non_negative_parafac_hals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorly Nonnegative Parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.4683462083339691\n",
      "iteration 1, reconstraction error: 0.3480120003223419, decrease = 0.1203342080116272\n",
      "iteration 2, reconstraction error: 0.2908419966697693, decrease = 0.05717000365257263\n",
      "iteration 3, reconstraction error: 0.26572519540786743, decrease = 0.025116801261901855\n",
      "iteration 4, reconstraction error: 0.25143569707870483, decrease = 0.014289498329162598\n",
      "iteration 5, reconstraction error: 0.2417619824409485, decrease = 0.009673714637756348\n",
      "iteration 6, reconstraction error: 0.23449958860874176, decrease = 0.007262393832206726\n",
      "iteration 7, reconstraction error: 0.22867494821548462, decrease = 0.005824640393257141\n",
      "iteration 8, reconstraction error: 0.22378763556480408, decrease = 0.004887312650680542\n",
      "iteration 9, reconstraction error: 0.21954494714736938, decrease = 0.004242688417434692\n",
      "iteration 10, reconstraction error: 0.21576501429080963, decrease = 0.0037799328565597534\n",
      "iteration 11, reconstraction error: 0.2123255431652069, decrease = 0.003439471125602722\n",
      "iteration 12, reconstraction error: 0.20914162695407867, decrease = 0.003183916211128235\n",
      "iteration 13, reconstraction error: 0.20615611970424652, decrease = 0.0029855072498321533\n",
      "iteration 14, reconstraction error: 0.20332853496074677, decrease = 0.002827584743499756\n",
      "iteration 15, reconstraction error: 0.20062915980815887, decrease = 0.0026993751525878906\n",
      "iteration 16, reconstraction error: 0.19804008305072784, decrease = 0.0025890767574310303\n",
      "iteration 17, reconstraction error: 0.19554699957370758, decrease = 0.0024930834770202637\n",
      "iteration 18, reconstraction error: 0.19314080476760864, decrease = 0.002406194806098938\n",
      "iteration 19, reconstraction error: 0.19081540405750275, decrease = 0.002325400710105896\n",
      "iteration 20, reconstraction error: 0.18856924772262573, decrease = 0.002246156334877014\n",
      "iteration 21, reconstraction error: 0.18639688193798065, decrease = 0.0021723657846450806\n",
      "iteration 22, reconstraction error: 0.1843004673719406, decrease = 0.002096414566040039\n",
      "iteration 23, reconstraction error: 0.1822788268327713, decrease = 0.0020216405391693115\n",
      "iteration 24, reconstraction error: 0.18033014237880707, decrease = 0.0019486844539642334\n",
      "iteration 25, reconstraction error: 0.17845898866653442, decrease = 0.001871153712272644\n",
      "iteration 26, reconstraction error: 0.17666123807430267, decrease = 0.0017977505922317505\n",
      "iteration 27, reconstraction error: 0.17493559420108795, decrease = 0.0017256438732147217\n",
      "iteration 28, reconstraction error: 0.17328377068042755, decrease = 0.0016518235206604004\n",
      "iteration 29, reconstraction error: 0.17170201241970062, decrease = 0.0015817582607269287\n",
      "iteration 30, reconstraction error: 0.1701899766921997, decrease = 0.0015120357275009155\n",
      "iteration 31, reconstraction error: 0.1687440574169159, decrease = 0.0014459192752838135\n",
      "iteration 32, reconstraction error: 0.1673603653907776, decrease = 0.0013836920261383057\n",
      "iteration 33, reconstraction error: 0.16603904962539673, decrease = 0.0013213157653808594\n",
      "iteration 34, reconstraction error: 0.16477267444133759, decrease = 0.001266375184059143\n",
      "iteration 35, reconstraction error: 0.16356059908866882, decrease = 0.0012120753526687622\n",
      "iteration 36, reconstraction error: 0.1623978316783905, decrease = 0.0011627674102783203\n",
      "iteration 37, reconstraction error: 0.16127966344356537, decrease = 0.0011181682348251343\n",
      "iteration 38, reconstraction error: 0.16020557284355164, decrease = 0.001074090600013733\n",
      "iteration 39, reconstraction error: 0.15916863083839417, decrease = 0.0010369420051574707\n",
      "iteration 40, reconstraction error: 0.15816615521907806, decrease = 0.001002475619316101\n",
      "iteration 41, reconstraction error: 0.1571958363056183, decrease = 0.0009703189134597778\n",
      "iteration 42, reconstraction error: 0.15625375509262085, decrease = 0.0009420812129974365\n",
      "iteration 43, reconstraction error: 0.15533700585365295, decrease = 0.0009167492389678955\n",
      "iteration 44, reconstraction error: 0.15444494783878326, decrease = 0.0008920580148696899\n",
      "iteration 45, reconstraction error: 0.15357504785060883, decrease = 0.0008698999881744385\n",
      "iteration 46, reconstraction error: 0.15272459387779236, decrease = 0.0008504539728164673\n",
      "iteration 47, reconstraction error: 0.15189187228679657, decrease = 0.0008327215909957886\n",
      "iteration 48, reconstraction error: 0.15107564628124237, decrease = 0.0008162260055541992\n",
      "iteration 49, reconstraction error: 0.1502782553434372, decrease = 0.0007973909378051758\n",
      "iteration 50, reconstraction error: 0.14949530363082886, decrease = 0.0007829517126083374\n",
      "iteration 51, reconstraction error: 0.14872702956199646, decrease = 0.0007682740688323975\n",
      "iteration 52, reconstraction error: 0.14797155559062958, decrease = 0.0007554739713668823\n",
      "iteration 53, reconstraction error: 0.1472322642803192, decrease = 0.0007392913103103638\n",
      "iteration 54, reconstraction error: 0.14650726318359375, decrease = 0.0007250010967254639\n",
      "iteration 55, reconstraction error: 0.1457941085100174, decrease = 0.000713154673576355\n",
      "iteration 56, reconstraction error: 0.14509616792201996, decrease = 0.0006979405879974365\n",
      "iteration 57, reconstraction error: 0.14440777897834778, decrease = 0.0006883889436721802\n",
      "iteration 58, reconstraction error: 0.14373447000980377, decrease = 0.0006733089685440063\n",
      "iteration 59, reconstraction error: 0.14307373762130737, decrease = 0.0006607323884963989\n",
      "iteration 60, reconstraction error: 0.1424241065979004, decrease = 0.0006496310234069824\n",
      "iteration 61, reconstraction error: 0.14178574085235596, decrease = 0.0006383657455444336\n",
      "iteration 62, reconstraction error: 0.141158789396286, decrease = 0.0006269514560699463\n",
      "iteration 63, reconstraction error: 0.14054231345653534, decrease = 0.0006164759397506714\n",
      "iteration 64, reconstraction error: 0.13993589580059052, decrease = 0.0006064176559448242\n",
      "iteration 65, reconstraction error: 0.13933852314949036, decrease = 0.0005973726511001587\n",
      "iteration 66, reconstraction error: 0.13874979317188263, decrease = 0.000588729977607727\n",
      "iteration 67, reconstraction error: 0.13817091286182404, decrease = 0.0005788803100585938\n",
      "iteration 68, reconstraction error: 0.13760031759738922, decrease = 0.0005705952644348145\n",
      "iteration 69, reconstraction error: 0.13703586161136627, decrease = 0.0005644559860229492\n",
      "iteration 70, reconstraction error: 0.13648158311843872, decrease = 0.0005542784929275513\n",
      "iteration 71, reconstraction error: 0.13593246042728424, decrease = 0.00054912269115448\n",
      "iteration 72, reconstraction error: 0.13539087772369385, decrease = 0.0005415827035903931\n",
      "iteration 73, reconstraction error: 0.13485634326934814, decrease = 0.0005345344543457031\n",
      "iteration 74, reconstraction error: 0.1343289166688919, decrease = 0.0005274266004562378\n",
      "iteration 75, reconstraction error: 0.13380810618400574, decrease = 0.0005208104848861694\n",
      "iteration 76, reconstraction error: 0.13329344987869263, decrease = 0.0005146563053131104\n",
      "iteration 77, reconstraction error: 0.1327861249446869, decrease = 0.0005073249340057373\n",
      "iteration 78, reconstraction error: 0.1322856992483139, decrease = 0.0005004256963729858\n",
      "iteration 79, reconstraction error: 0.13178983330726624, decrease = 0.0004958659410476685\n",
      "iteration 80, reconstraction error: 0.13130155205726624, decrease = 0.00048828125\n",
      "iteration 81, reconstraction error: 0.13081739842891693, decrease = 0.0004841536283493042\n",
      "iteration 82, reconstraction error: 0.13034097850322723, decrease = 0.00047641992568969727\n",
      "iteration 83, reconstraction error: 0.12987177073955536, decrease = 0.000469207763671875\n",
      "iteration 84, reconstraction error: 0.1294056624174118, decrease = 0.0004661083221435547\n",
      "iteration 85, reconstraction error: 0.12894752621650696, decrease = 0.0004581362009048462\n",
      "iteration 86, reconstraction error: 0.1284950077533722, decrease = 0.0004525184631347656\n",
      "iteration 87, reconstraction error: 0.12804755568504333, decrease = 0.0004474520683288574\n",
      "iteration 88, reconstraction error: 0.12760582566261292, decrease = 0.0004417300224304199\n",
      "iteration 89, reconstraction error: 0.12717051804065704, decrease = 0.0004353076219558716\n",
      "iteration 90, reconstraction error: 0.1267404407262802, decrease = 0.00043007731437683105\n",
      "iteration 91, reconstraction error: 0.1263156682252884, decrease = 0.0004247725009918213\n",
      "iteration 92, reconstraction error: 0.12589626014232635, decrease = 0.00041940808296203613\n",
      "iteration 93, reconstraction error: 0.1254822462797165, decrease = 0.0004140138626098633\n",
      "iteration 94, reconstraction error: 0.12507493793964386, decrease = 0.00040730834007263184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 95, reconstraction error: 0.12467377632856369, decrease = 0.0004011616110801697\n",
      "iteration 96, reconstraction error: 0.12427694350481033, decrease = 0.00039683282375335693\n",
      "iteration 97, reconstraction error: 0.12388699501752853, decrease = 0.0003899484872817993\n",
      "iteration 98, reconstraction error: 0.12350334972143173, decrease = 0.00038364529609680176\n",
      "iteration 99, reconstraction error: 0.12312419712543488, decrease = 0.0003791525959968567\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "weightsnon, factorsnon = non_negative_parafac(tensor, rank=rank, init=init, tol=10e-8,verbose=1)\n",
    "cp_reconstructionnon = tl.cp_to_tensor((weightsnon, factorsnon))\n",
    "time_tensorlynon = time.time()-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hals in Tensorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.24565155804157257\n",
      "iteration 1, reconstruction error: 0.12981973588466644, decrease = 0.11583182215690613\n",
      "iteration 2, reconstruction error: 0.11440639197826385, decrease = 0.015413343906402588\n",
      "iteration 3, reconstruction error: 0.1054520457983017, decrease = 0.008954346179962158\n",
      "iteration 4, reconstruction error: 0.09911470115184784, decrease = 0.006337344646453857\n",
      "iteration 5, reconstruction error: 0.09431571513414383, decrease = 0.00479898601770401\n",
      "iteration 6, reconstruction error: 0.09063030779361725, decrease = 0.003685407340526581\n",
      "iteration 7, reconstruction error: 0.08785497397184372, decrease = 0.002775333821773529\n",
      "iteration 8, reconstruction error: 0.08559278398752213, decrease = 0.0022621899843215942\n",
      "iteration 9, reconstruction error: 0.083652563393116, decrease = 0.001940220594406128\n",
      "iteration 10, reconstruction error: 0.0818268209695816, decrease = 0.0018257424235343933\n",
      "iteration 11, reconstruction error: 0.080350860953331, decrease = 0.0014759600162506104\n",
      "iteration 12, reconstruction error: 0.07915204018354416, decrease = 0.0011988207697868347\n",
      "iteration 13, reconstruction error: 0.0782976821064949, decrease = 0.0008543580770492554\n",
      "iteration 14, reconstruction error: 0.07766824960708618, decrease = 0.0006294324994087219\n",
      "iteration 15, reconstruction error: 0.07724007219076157, decrease = 0.0004281774163246155\n",
      "iteration 16, reconstruction error: 0.07683782279491425, decrease = 0.00040224939584732056\n",
      "iteration 17, reconstruction error: 0.07653196156024933, decrease = 0.000305861234664917\n",
      "iteration 18, reconstruction error: 0.07624626159667969, decrease = 0.0002856999635696411\n",
      "iteration 19, reconstruction error: 0.07586638629436493, decrease = 0.0003798753023147583\n",
      "iteration 20, reconstruction error: 0.07551957666873932, decrease = 0.00034680962562561035\n",
      "iteration 21, reconstruction error: 0.07520008087158203, decrease = 0.0003194957971572876\n",
      "iteration 22, reconstruction error: 0.07494040578603745, decrease = 0.0002596750855445862\n",
      "iteration 23, reconstruction error: 0.07471413165330887, decrease = 0.00022627413272857666\n",
      "iteration 24, reconstruction error: 0.0745309516787529, decrease = 0.00018317997455596924\n",
      "iteration 25, reconstruction error: 0.0744590163230896, decrease = 7.193535566329956e-05\n",
      "iteration 26, reconstruction error: 0.07441206276416779, decrease = 4.6953558921813965e-05\n",
      "iteration 27, reconstruction error: 0.07436820864677429, decrease = 4.385411739349365e-05\n",
      "iteration 28, reconstruction error: 0.07435149699449539, decrease = 1.6711652278900146e-05\n",
      "iteration 29, reconstruction error: 0.07436089962720871, decrease = -9.402632713317871e-06\n",
      "iteration 30, reconstruction error: 0.07435046136379242, decrease = 1.0438263416290283e-05\n",
      "iteration 31, reconstruction error: 0.07434418797492981, decrease = 6.273388862609863e-06\n",
      "iteration 32, reconstruction error: 0.07434941083192825, decrease = -5.2228569984436035e-06\n",
      "iteration 33, reconstruction error: 0.07434731721878052, decrease = 2.0936131477355957e-06\n",
      "iteration 34, reconstruction error: 0.07432433217763901, decrease = 2.298504114151001e-05\n",
      "iteration 35, reconstruction error: 0.07431492954492569, decrease = 9.402632713317871e-06\n",
      "iteration 36, reconstruction error: 0.07433374226093292, decrease = -1.8812716007232666e-05\n",
      "iteration 37, reconstruction error: 0.07431179285049438, decrease = 2.1949410438537598e-05\n",
      "iteration 38, reconstruction error: 0.07429507374763489, decrease = 1.671910285949707e-05\n",
      "iteration 39, reconstruction error: 0.07426684349775314, decrease = 2.8230249881744385e-05\n",
      "iteration 40, reconstruction error: 0.07422813773155212, decrease = 3.870576620101929e-05\n",
      "iteration 41, reconstruction error: 0.07418836653232574, decrease = 3.9771199226379395e-05\n",
      "iteration 42, reconstruction error: 0.07414962351322174, decrease = 3.8743019104003906e-05\n",
      "iteration 43, reconstruction error: 0.07411818951368332, decrease = 3.143399953842163e-05\n",
      "iteration 44, reconstruction error: 0.0740773156285286, decrease = 4.087388515472412e-05\n",
      "iteration 45, reconstruction error: 0.07404060661792755, decrease = 3.67090106010437e-05\n",
      "iteration 46, reconstruction error: 0.07399549335241318, decrease = 4.511326551437378e-05\n",
      "iteration 47, reconstruction error: 0.07393983751535416, decrease = 5.5655837059020996e-05\n",
      "iteration 48, reconstruction error: 0.07389255613088608, decrease = 4.728138446807861e-05\n",
      "iteration 49, reconstruction error: 0.07384524494409561, decrease = 4.731118679046631e-05\n",
      "iteration 50, reconstruction error: 0.073796845972538, decrease = 4.839897155761719e-05\n",
      "iteration 51, reconstruction error: 0.07375579327344894, decrease = 4.105269908905029e-05\n",
      "iteration 52, reconstruction error: 0.07372945547103882, decrease = 2.6337802410125732e-05\n",
      "iteration 53, reconstruction error: 0.07371892780065536, decrease = 1.0527670383453369e-05\n",
      "iteration 54, reconstruction error: 0.07368626445531845, decrease = 3.266334533691406e-05\n",
      "iteration 55, reconstruction error: 0.07365568727254868, decrease = 3.057718276977539e-05\n",
      "iteration 56, reconstruction error: 0.07361455261707306, decrease = 4.1134655475616455e-05\n",
      "iteration 57, reconstruction error: 0.07357972860336304, decrease = 3.482401371002197e-05\n",
      "iteration 58, reconstruction error: 0.07354804873466492, decrease = 3.167986869812012e-05\n",
      "iteration 59, reconstruction error: 0.07349734753370285, decrease = 5.070120096206665e-05\n",
      "iteration 60, reconstruction error: 0.07346352934837341, decrease = 3.3818185329437256e-05\n",
      "iteration 61, reconstruction error: 0.0734381452202797, decrease = 2.5384128093719482e-05\n",
      "iteration 62, reconstruction error: 0.07341381907463074, decrease = 2.43261456489563e-05\n",
      "iteration 63, reconstruction error: 0.07339582592248917, decrease = 1.7993152141571045e-05\n",
      "iteration 64, reconstruction error: 0.07337995618581772, decrease = 1.5869736671447754e-05\n",
      "iteration 65, reconstruction error: 0.07334289699792862, decrease = 3.705918788909912e-05\n",
      "iteration 66, reconstruction error: 0.07329099625349045, decrease = 5.190074443817139e-05\n",
      "iteration 67, reconstruction error: 0.07325071096420288, decrease = 4.028528928756714e-05\n",
      "iteration 68, reconstruction error: 0.0732220858335495, decrease = 2.8625130653381348e-05\n",
      "iteration 69, reconstruction error: 0.07318919152021408, decrease = 3.28943133354187e-05\n",
      "iteration 70, reconstruction error: 0.07314886152744293, decrease = 4.032999277114868e-05\n",
      "iteration 71, reconstruction error: 0.07309574633836746, decrease = 5.311518907546997e-05\n",
      "iteration 72, reconstruction error: 0.07306280732154846, decrease = 3.2939016819000244e-05\n",
      "iteration 73, reconstruction error: 0.07302665710449219, decrease = 3.6150217056274414e-05\n",
      "iteration 74, reconstruction error: 0.07298941910266876, decrease = 3.723800182342529e-05\n",
      "iteration 75, reconstruction error: 0.0729479119181633, decrease = 4.1507184505462646e-05\n",
      "iteration 76, reconstruction error: 0.07291276752948761, decrease = 3.51443886756897e-05\n",
      "iteration 77, reconstruction error: 0.07288613170385361, decrease = 2.6635825634002686e-05\n",
      "iteration 78, reconstruction error: 0.07286268472671509, decrease = 2.3446977138519287e-05\n",
      "iteration 79, reconstruction error: 0.07284136116504669, decrease = 2.1323561668395996e-05\n",
      "iteration 80, reconstruction error: 0.07282750308513641, decrease = 1.385807991027832e-05\n",
      "iteration 81, reconstruction error: 0.07279550284147263, decrease = 3.200024366378784e-05\n",
      "iteration 82, reconstruction error: 0.07275815308094025, decrease = 3.734976053237915e-05\n",
      "iteration 83, reconstruction error: 0.07272825390100479, decrease = 2.9899179935455322e-05\n",
      "iteration 84, reconstruction error: 0.07270155102014542, decrease = 2.6702880859375e-05\n",
      "iteration 85, reconstruction error: 0.07267911732196808, decrease = 2.2433698177337646e-05\n",
      "iteration 86, reconstruction error: 0.07265773415565491, decrease = 2.1383166313171387e-05\n",
      "iteration 87, reconstruction error: 0.07263635843992233, decrease = 2.1375715732574463e-05\n",
      "iteration 88, reconstruction error: 0.07261389493942261, decrease = 2.2463500499725342e-05\n",
      "iteration 89, reconstruction error: 0.0725935772061348, decrease = 2.031773328781128e-05\n",
      "iteration 90, reconstruction error: 0.0725807398557663, decrease = 1.2837350368499756e-05\n",
      "iteration 91, reconstruction error: 0.07256253808736801, decrease = 1.8201768398284912e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 92, reconstruction error: 0.07254113256931305, decrease = 2.1405518054962158e-05\n",
      "iteration 93, reconstruction error: 0.07252292335033417, decrease = 1.8209218978881836e-05\n",
      "iteration 94, reconstruction error: 0.07250150293111801, decrease = 2.1420419216156006e-05\n",
      "iteration 95, reconstruction error: 0.07247686386108398, decrease = 2.46390700340271e-05\n",
      "iteration 96, reconstruction error: 0.07246185839176178, decrease = 1.500546932220459e-05\n",
      "iteration 97, reconstruction error: 0.07244792580604553, decrease = 1.3932585716247559e-05\n",
      "iteration 98, reconstruction error: 0.07242970168590546, decrease = 1.8224120140075684e-05\n",
      "iteration 99, reconstruction error: 0.07241146266460419, decrease = 1.823902130126953e-05\n"
     ]
    }
   ],
   "source": [
    "ticnew = time.time()\n",
    "nncp=CPNN_HALS(rank=rank,init=init,verbose=1)\n",
    "cptensor=nncp.fit_transform(tensor)\n",
    "cp_reconstruction_hals = tl.cp_to_tensor(cptensor)\n",
    "time_class = time.time()-ticnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for tensorly noncp: 9.014447450637817\n",
      "time for hals in tensorly: 76.52248501777649\n",
      "RMSE tensorly ncp: tf.Tensor(14.429204, shape=(), dtype=float32)\n",
      "RMSE Hals in tensorly: tf.Tensor(8.495953, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('time for tensorly noncp:'+' ' +str(time_tensorlynon))\n",
    "print('time for hals in tensorly:'+' ' +str(time_class))\n",
    "print('RMSE tensorly ncp:'+' ' +str(RMSE(tensor,cp_reconstructionnon)))\n",
    "print('RMSE Hals in tensorly:'+' ' +str(RMSE(tensor,cp_reconstruction_hals)))\n",
    "#errors_for_each(tensor,cp_reconstructionnon,cp_reconstruction_hals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Backend to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctuna/tensorly/tensorly/backend/pytorch_backend.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(data, dtype=dtype, device=device,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (list, axis=int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b0a7f599b3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_non_negative_parafac_hals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-84c2b6ac2332>\u001b[0m in \u001b[0;36mtest_non_negative_parafac_hals\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfixed_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mrec_svd_fixed_mode_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_negative_parafac_hals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_modes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mrec_svd_fixed_mode_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_negative_parafac_hals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_modes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Check if modified after 2 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorly/tensorly/decomposition/_nn_cp.py\u001b[0m in \u001b[0;36mnon_negative_parafac_hals\u001b[0;34m(tensor, rank, n_iter_max, init, svd, tol, sparsity_coefficients, fixed_modes, exact, verbose, return_errors, cvg_criterion)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m# Call the hals resolution with nnls, optimizing the current mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             factors[mode] = tl.transpose(\n\u001b[0;32m--> 391\u001b[0;31m                       hals_nnls(tl.transpose(mttkrp), pseudo_inverse, tl.transpose(factors[mode]),\n\u001b[0m\u001b[1;32m    392\u001b[0m                              n_iter_max=100,sparsity_coefficient=sparsity_coefficients[mode],exact=exact)[0])\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorly/tensorly/tenalg/proximal.py\u001b[0m in \u001b[0;36mhals_nnls\u001b[0;34m(UtM, UtU, V, n_iter_max, tol, sparsity_coefficient, normalize, nonzero_rows, exact)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# without sparsity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                     deltaV = tl.max([(UtM[k, :] - tl.dot(UtU[k, :], V)) / UtU[k, k],\n\u001b[0m\u001b[1;32m    216\u001b[0m                                          -V[k, :]], axis=0)\n\u001b[1;32m    217\u001b[0m                     \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdeltaV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorly/tensorly/backend/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_backend_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;31m# We don't use `functools.wraps` here because some of the dispatched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (list, axis=int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tl.set_backend('pytorch')\n",
    "tensor = tl.tensor(np.array(image,dtype=int))\n",
    "test_non_negative_parafac_hals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorly Nonnegative Parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "weightsnon, factorsnon = non_negative_parafac(tensor, rank=rank, init=init, tol=10e-8)\n",
    "cp_reconstructionnon = tl.cp_to_tensor((weightsnon, factorsnon))\n",
    "time_tensorlynon = time.time()-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hals in Tensorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticnew = time.time()\n",
    "nncp=CPNN_Hals(rank=rank,init=init)\n",
    "cptensor=nncp.fit_transform(tensor)\n",
    "cp_reconstruction_hals = nncp.cp_to_tensor()\n",
    "time_class = time.time()-ticnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time for tensorly noncp:'+' ' +str(time_tensorlynon))\n",
    "print('time for hals in tensorly:'+' ' +str(time_class))\n",
    "print('RMSE tensorly ncp:'+' ' +str(RMSE(tensor,cp_reconstructionnon)))\n",
    "print('RMSE Hals in tensorly:'+' ' +str(RMSE(tensor,cp_reconstruction_hals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Backend to Mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('mxnet')\n",
    "tensor = tl.tensor(np.array(image,dtype=int))\n",
    "test_non_negative_parafac_hals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
